{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** The architecture is based on a convolutional neural network (CNN) and a recurrent neural network (RNN). The CNN works as an encoder that generates a vector of features from the image supplied to the input. In this case a ResNet is used, but other types of architectures could also be valid.  The other part of the network is an RNN that works as a decoder, i.e. from the information received from the encoder it is able to generate image captions. It simply consists of an LSTM layer followed by a linear layer.\n",
    "\n",
    "Regarding the hyperparameters, they are inspired by the two papers provided. The batchsize is limited by the GPUs and allows to obtain more stable training. It starts with a value of 32 and as reasonable results are obtained, higher values are not tested. The threshold for vocabulary selection is increased to 10, to slightly reduce the number of tokens in the vocabulary and thus reduce the size of the word embedding. Finally, the dimensionality of image and word embeddings and the features in hidden state are set to 256. In the papers it is quoted that the size of both is 512. For our case, since it is an experiment with a limited number of hours of computation, it is decided to reduce it to obtain more immediate results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** CNN accepts RGB input images of 224 x 224 pxs, so images must be adapted to that size. On the other hand, data augmentation is a technique that improves the performance of CNNs by generating perturbations in the training images. This reduces overfitting, allowing the NN to generalize better. In this case, the transformations applied are horizontal/vertical random image shift and random horizontal flip. Other transformations could be convenient to apply such as rotations, image brightness, ... Finally, the ResNet neural network used is pre-trained with the ImageNet dataset, but the last layers are adapted to our problem This technique is known as Transfer Learning and allows to accelerate the training process of the CNN. So it makes sense that the input images are normalized as close as possible to the images used in the pre-trained model.\n",
    "\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** On the one hand, in CNN the ResNet model has been pre-trained, so only the layers that have been added to the model will be trained. Actually the pre-trained model could also be trained, and therefore would be more optimal, but in such a case, the training time would be longer. On the other hand, in the RNN it has been designed from scratch, so all layers must be trained.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** In the proposed papers, Adam and MRSProp are used, which are optimizers that automatically adapt the learning rate. In practice, these methods work very well. In this case, we have used Adam as the first alternative. Since the results have been satisfactory, other alternatives have not been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 429/414113 [00:00<01:36, 4280.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 895/414113 [00:00<01:34, 4387.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1369/414113 [00:00<01:32, 4485.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1839/414113 [00:00<01:30, 4545.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2316/414113 [00:00<01:29, 4608.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2782/414113 [00:00<01:28, 4622.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3257/414113 [00:00<01:28, 4655.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3745/414113 [00:00<01:26, 4718.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4219/414113 [00:00<01:26, 4724.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4702/414113 [00:01<01:26, 4753.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5193/414113 [00:01<01:25, 4797.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5667/414113 [00:01<01:25, 4778.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 6140/414113 [00:01<01:25, 4757.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6612/414113 [00:01<01:29, 4569.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7082/414113 [00:01<01:28, 4606.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7551/414113 [00:01<01:27, 4629.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8037/414113 [00:01<01:26, 4694.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8510/414113 [00:01<01:26, 4704.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8983/414113 [00:01<01:26, 4710.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9457/414113 [00:02<01:25, 4715.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9931/414113 [00:02<01:25, 4721.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10404/414113 [00:02<01:25, 4699.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10874/414113 [00:02<01:25, 4693.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11347/414113 [00:02<01:25, 4701.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11818/414113 [00:02<01:25, 4702.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12292/414113 [00:02<01:25, 4712.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12764/414113 [00:02<01:25, 4697.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13251/414113 [00:02<01:24, 4745.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13732/414113 [00:02<01:24, 4762.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14209/414113 [00:03<01:24, 4747.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14684/414113 [00:03<01:24, 4710.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 15162/414113 [00:03<01:24, 4730.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 15636/414113 [00:03<01:24, 4723.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16116/414113 [00:03<01:23, 4745.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16594/414113 [00:03<01:23, 4752.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17074/414113 [00:03<01:23, 4765.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17551/414113 [00:03<01:23, 4734.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18038/414113 [00:03<01:22, 4774.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18516/414113 [00:03<01:23, 4752.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 18992/414113 [00:04<01:23, 4737.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19466/414113 [00:04<01:26, 4587.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19935/414113 [00:04<01:25, 4616.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20410/414113 [00:04<01:24, 4653.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 20877/414113 [00:04<01:25, 4625.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21360/414113 [00:04<01:23, 4684.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21834/414113 [00:04<01:23, 4700.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22308/414113 [00:04<01:23, 4711.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 22798/414113 [00:04<01:22, 4763.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23275/414113 [00:04<01:22, 4729.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23749/414113 [00:05<01:23, 4693.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24229/414113 [00:05<01:22, 4723.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24702/414113 [00:05<01:22, 4702.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25183/414113 [00:05<01:22, 4731.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25669/414113 [00:05<01:21, 4769.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26159/414113 [00:05<01:20, 4806.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26647/414113 [00:05<01:20, 4828.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27131/414113 [00:05<01:20, 4815.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27616/414113 [00:05<01:20, 4823.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28099/414113 [00:05<01:21, 4760.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28589/414113 [00:06<01:20, 4799.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29070/414113 [00:06<01:20, 4790.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29550/414113 [00:06<01:20, 4770.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30028/414113 [00:06<01:20, 4773.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30507/414113 [00:06<01:20, 4775.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 31002/414113 [00:06<01:19, 4824.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31491/414113 [00:06<01:19, 4840.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31976/414113 [00:06<01:18, 4838.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32460/414113 [00:06<01:19, 4787.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32941/414113 [00:06<01:19, 4792.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33424/414113 [00:07<01:19, 4801.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33917/414113 [00:07<01:18, 4839.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34408/414113 [00:07<01:18, 4858.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34894/414113 [00:07<01:18, 4834.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35379/414113 [00:07<01:18, 4837.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35863/414113 [00:07<01:18, 4821.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 36346/414113 [00:07<01:18, 4787.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 36825/414113 [00:07<01:19, 4774.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37308/414113 [00:07<01:18, 4787.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37787/414113 [00:07<01:18, 4786.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38271/414113 [00:08<01:18, 4800.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38752/414113 [00:08<01:18, 4802.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 39233/414113 [00:08<01:18, 4768.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 39710/414113 [00:08<01:18, 4746.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40198/414113 [00:08<01:18, 4785.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40683/414113 [00:08<01:17, 4800.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 41164/414113 [00:08<01:18, 4764.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 41641/414113 [00:08<01:18, 4749.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 42117/414113 [00:08<01:18, 4723.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 42590/414113 [00:08<01:18, 4707.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 43065/414113 [00:09<01:18, 4719.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 43538/414113 [00:09<01:18, 4718.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44010/414113 [00:09<01:19, 4657.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44477/414113 [00:09<01:19, 4658.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44944/414113 [00:09<01:19, 4630.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45426/414113 [00:09<01:18, 4683.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45902/414113 [00:09<01:18, 4704.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 46384/414113 [00:09<01:17, 4736.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 46864/414113 [00:09<01:17, 4752.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 47340/414113 [00:09<01:17, 4735.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 47820/414113 [00:10<01:17, 4752.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 48300/414113 [00:10<01:16, 4766.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 48777/414113 [00:10<01:17, 4726.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49253/414113 [00:10<01:17, 4735.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49731/414113 [00:10<01:16, 4747.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 50213/414113 [00:10<01:16, 4766.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 50690/414113 [00:10<01:19, 4549.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 51168/414113 [00:10<01:18, 4615.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 51638/414113 [00:10<01:18, 4638.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 52115/414113 [00:11<01:17, 4676.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 52599/414113 [00:11<01:16, 4724.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 53078/414113 [00:11<01:16, 4742.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 53553/414113 [00:11<01:16, 4702.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54032/414113 [00:11<01:16, 4725.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54505/414113 [00:11<01:16, 4709.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54977/414113 [00:11<01:16, 4707.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 55452/414113 [00:11<01:15, 4720.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 55936/414113 [00:11<01:15, 4753.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 56412/414113 [00:11<01:15, 4744.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 56893/414113 [00:12<01:15, 4761.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 57372/414113 [00:12<01:14, 4768.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 57856/414113 [00:12<01:14, 4789.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 58335/414113 [00:12<01:14, 4778.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 58813/414113 [00:12<01:14, 4773.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 59291/414113 [00:12<01:14, 4772.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 59779/414113 [00:12<01:13, 4802.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 60263/414113 [00:12<01:13, 4812.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 60745/414113 [00:12<01:13, 4802.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 61226/414113 [00:12<01:13, 4794.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 61706/414113 [00:13<01:13, 4791.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 62186/414113 [00:13<01:13, 4783.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 62665/414113 [00:13<01:13, 4767.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 63149/414113 [00:13<01:13, 4786.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 63628/414113 [00:13<01:13, 4784.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 64119/414113 [00:13<01:12, 4821.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 64602/414113 [00:13<01:13, 4783.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 65081/414113 [00:13<01:13, 4775.71it/s]\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      " 16%|█▌        | 65559/414113 [00:14<03:09, 1840.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66026/414113 [00:14<02:34, 2249.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66515/414113 [00:14<02:09, 2684.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 67000/414113 [00:14<01:52, 3098.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 67465/414113 [00:14<01:40, 3443.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 67949/414113 [00:14<01:31, 3768.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 68431/414113 [00:14<01:25, 4030.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 68896/414113 [00:15<01:22, 4180.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 69363/414113 [00:15<01:19, 4314.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 69841/414113 [00:15<01:17, 4443.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 70331/414113 [00:15<01:15, 4570.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 70822/414113 [00:15<01:13, 4666.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71315/414113 [00:15<01:12, 4741.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71799/414113 [00:15<01:11, 4758.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 72282/414113 [00:15<01:11, 4751.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 72767/414113 [00:15<01:11, 4778.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 73254/414113 [00:15<01:10, 4803.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 73737/414113 [00:16<01:11, 4772.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74216/414113 [00:16<01:11, 4772.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74695/414113 [00:16<01:11, 4742.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75171/414113 [00:16<01:11, 4736.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75646/414113 [00:16<01:11, 4717.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 76125/414113 [00:16<01:11, 4737.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 76600/414113 [00:16<01:15, 4448.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 77080/414113 [00:16<01:14, 4547.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 77563/414113 [00:16<01:12, 4626.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 78046/414113 [00:16<01:11, 4683.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 78526/414113 [00:17<01:11, 4716.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79007/414113 [00:17<01:10, 4740.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79483/414113 [00:17<01:10, 4746.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79962/414113 [00:17<01:10, 4757.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 80439/414113 [00:17<01:10, 4743.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 80915/414113 [00:17<01:10, 4747.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 81391/414113 [00:17<01:10, 4729.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 81867/414113 [00:17<01:10, 4736.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 82351/414113 [00:17<01:09, 4766.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 82829/414113 [00:17<01:09, 4768.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83325/414113 [00:18<01:08, 4824.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83821/414113 [00:18<01:07, 4861.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 84308/414113 [00:18<01:08, 4848.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 84794/414113 [00:18<01:08, 4820.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 85282/414113 [00:18<01:07, 4836.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 85766/414113 [00:18<01:08, 4789.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 86246/414113 [00:18<01:08, 4770.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 86730/414113 [00:18<01:08, 4789.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87216/414113 [00:18<01:07, 4810.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87698/414113 [00:19<01:07, 4805.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88186/414113 [00:19<01:07, 4826.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88679/414113 [00:19<01:07, 4856.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 89165/414113 [00:19<01:07, 4828.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 89660/414113 [00:19<01:06, 4862.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 90147/414113 [00:19<01:06, 4841.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 90632/414113 [00:19<01:07, 4816.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 91114/414113 [00:19<01:09, 4677.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 91594/414113 [00:19<01:08, 4711.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 92084/414113 [00:19<01:07, 4766.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 92564/414113 [00:20<01:07, 4775.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 93051/414113 [00:20<01:06, 4801.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 93532/414113 [00:20<01:06, 4796.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94014/414113 [00:20<01:06, 4803.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94506/414113 [00:20<01:06, 4834.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94990/414113 [00:20<01:06, 4826.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 95478/414113 [00:20<01:05, 4841.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 95963/414113 [00:20<01:06, 4806.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 96451/414113 [00:20<01:05, 4827.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 96938/414113 [00:20<01:05, 4838.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 97422/414113 [00:21<01:05, 4837.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 97909/414113 [00:21<01:05, 4845.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 98394/414113 [00:21<01:05, 4833.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 98878/414113 [00:21<01:05, 4793.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 99365/414113 [00:21<01:05, 4815.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 99861/414113 [00:21<01:04, 4856.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100351/414113 [00:21<01:04, 4868.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100838/414113 [00:21<01:04, 4863.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 101325/414113 [00:21<01:04, 4835.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 101809/414113 [00:21<01:05, 4800.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102290/414113 [00:22<01:05, 4777.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102778/414113 [00:22<01:04, 4804.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 103259/414113 [00:22<01:05, 4766.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 103747/414113 [00:22<01:04, 4799.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 104228/414113 [00:22<01:04, 4772.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 104708/414113 [00:22<01:04, 4779.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 105187/414113 [00:22<01:04, 4768.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 105664/414113 [00:22<01:04, 4762.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106148/414113 [00:22<01:04, 4785.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106627/414113 [00:22<01:04, 4737.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 107102/414113 [00:23<01:04, 4740.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 107577/414113 [00:23<01:04, 4728.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 108050/414113 [00:23<01:04, 4713.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 108522/414113 [00:23<01:04, 4708.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 109004/414113 [00:23<01:04, 4738.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 109478/414113 [00:23<01:04, 4725.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 109976/414113 [00:23<01:03, 4797.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110457/414113 [00:23<01:03, 4798.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110938/414113 [00:23<01:03, 4795.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 111430/414113 [00:23<01:02, 4830.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 111917/414113 [00:24<01:02, 4840.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112402/414113 [00:24<01:02, 4818.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112884/414113 [00:24<01:02, 4808.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 113370/414113 [00:24<01:02, 4821.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 113853/414113 [00:24<01:02, 4780.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114337/414113 [00:24<01:02, 4796.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114817/414113 [00:24<01:02, 4769.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 115295/414113 [00:24<01:03, 4704.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 115774/414113 [00:24<01:03, 4729.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 116248/414113 [00:24<01:03, 4684.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 116721/414113 [00:25<01:03, 4696.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 117191/414113 [00:25<01:03, 4696.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 117666/414113 [00:25<01:02, 4712.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 118138/414113 [00:25<01:03, 4696.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 118608/414113 [00:25<01:03, 4683.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 119077/414113 [00:25<01:03, 4681.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 119546/414113 [00:25<01:05, 4500.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120016/414113 [00:25<01:04, 4557.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120490/414113 [00:25<01:03, 4609.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120974/414113 [00:25<01:02, 4673.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 121448/414113 [00:26<01:02, 4692.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 121927/414113 [00:26<01:01, 4719.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 122405/414113 [00:26<01:01, 4737.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 122880/414113 [00:26<01:01, 4727.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123354/414113 [00:26<01:01, 4725.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123832/414113 [00:26<01:01, 4741.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 124319/414113 [00:26<01:00, 4779.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 124798/414113 [00:26<01:00, 4767.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 125275/414113 [00:26<01:00, 4766.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 125752/414113 [00:26<01:01, 4726.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 126232/414113 [00:27<01:00, 4746.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 126712/414113 [00:27<01:00, 4761.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 127192/414113 [00:27<01:00, 4770.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 127670/414113 [00:27<01:00, 4748.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128145/414113 [00:27<01:00, 4747.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128620/414113 [00:27<01:00, 4745.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 129095/414113 [00:27<01:00, 4734.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 129583/414113 [00:27<00:59, 4774.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 130068/414113 [00:27<00:59, 4795.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 130548/414113 [00:27<00:59, 4761.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131029/414113 [00:28<00:59, 4774.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131507/414113 [00:28<00:59, 4768.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131987/414113 [00:28<00:59, 4775.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 132465/414113 [00:28<00:59, 4747.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 132940/414113 [00:28<00:59, 4689.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133410/414113 [00:28<00:59, 4692.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133880/414113 [00:28<00:59, 4691.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 134350/414113 [00:28<01:00, 4652.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 134832/414113 [00:28<00:59, 4701.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 135303/414113 [00:29<00:59, 4696.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 135790/414113 [00:29<00:58, 4744.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 136273/414113 [00:29<00:58, 4767.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 136750/414113 [00:29<00:58, 4738.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137225/414113 [00:29<00:58, 4733.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137699/414113 [00:29<00:58, 4729.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 138180/414113 [00:29<00:58, 4750.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 138656/414113 [00:29<00:58, 4700.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 139129/414113 [00:29<00:58, 4706.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 139614/414113 [00:29<00:57, 4746.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 140089/414113 [00:30<00:57, 4745.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 140564/414113 [00:30<00:57, 4725.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141037/414113 [00:30<00:57, 4717.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141509/414113 [00:30<00:58, 4698.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141987/414113 [00:30<00:57, 4722.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 142460/414113 [00:30<00:57, 4683.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 142929/414113 [00:30<00:57, 4677.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 143397/414113 [00:30<00:59, 4578.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 143872/414113 [00:30<00:58, 4628.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 144347/414113 [00:30<00:57, 4662.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 144814/414113 [00:31<00:57, 4659.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145288/414113 [00:31<00:57, 4682.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145763/414113 [00:31<00:57, 4700.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146234/414113 [00:31<00:57, 4689.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146704/414113 [00:31<00:57, 4670.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 147172/414113 [00:31<00:57, 4647.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 147653/414113 [00:31<00:56, 4695.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 148139/414113 [00:31<00:56, 4741.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 148614/414113 [00:31<00:56, 4724.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149090/414113 [00:31<00:55, 4733.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149571/414113 [00:32<00:55, 4755.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 150054/414113 [00:32<00:55, 4776.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 150537/414113 [00:32<00:55, 4790.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 151017/414113 [00:32<00:55, 4743.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 151503/414113 [00:32<00:54, 4777.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 151991/414113 [00:32<00:54, 4806.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 152472/414113 [00:32<00:54, 4797.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 152955/414113 [00:32<00:54, 4807.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 153450/414113 [00:32<00:53, 4847.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 153940/414113 [00:32<00:53, 4862.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154427/414113 [00:33<00:53, 4863.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154914/414113 [00:33<00:53, 4819.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 155397/414113 [00:33<00:54, 4784.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 155876/414113 [00:33<00:54, 4758.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 156362/414113 [00:33<00:53, 4788.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 156842/414113 [00:33<00:53, 4783.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 157324/414113 [00:33<00:53, 4794.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 157804/414113 [00:33<00:54, 4722.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 158283/414113 [00:33<00:53, 4740.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 158758/414113 [00:33<00:53, 4732.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 159241/414113 [00:34<00:53, 4760.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 159732/414113 [00:34<00:52, 4801.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 160213/414113 [00:34<00:53, 4789.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 160693/414113 [00:34<00:52, 4786.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161182/414113 [00:34<00:52, 4816.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161664/414113 [00:34<00:52, 4811.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 162150/414113 [00:34<00:52, 4825.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 162633/414113 [00:34<00:52, 4812.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 163115/414113 [00:34<00:52, 4802.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 163596/414113 [00:34<00:52, 4790.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164076/414113 [00:35<00:52, 4778.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164554/414113 [00:35<00:52, 4772.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 165032/414113 [00:35<00:52, 4753.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 165508/414113 [00:35<00:53, 4686.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 165977/414113 [00:35<00:53, 4650.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 166443/414113 [00:35<00:53, 4631.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 166907/414113 [00:35<00:53, 4623.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 167377/414113 [00:35<00:53, 4644.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 167848/414113 [00:35<00:52, 4661.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168326/414113 [00:35<00:52, 4692.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168796/414113 [00:36<00:52, 4668.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169263/414113 [00:36<00:52, 4655.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169730/414113 [00:36<00:52, 4659.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 170200/414113 [00:36<00:52, 4670.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 170693/414113 [00:36<00:51, 4745.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 171168/414113 [00:36<00:51, 4739.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 171644/414113 [00:36<00:51, 4745.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172119/414113 [00:36<00:51, 4739.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172594/414113 [00:36<00:51, 4729.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 173068/414113 [00:36<00:51, 4720.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 173541/414113 [00:37<00:51, 4691.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174011/414113 [00:37<00:51, 4676.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174481/414113 [00:37<00:51, 4680.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174950/414113 [00:37<00:53, 4444.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 175421/414113 [00:37<00:52, 4519.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 175897/414113 [00:37<00:51, 4588.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 176367/414113 [00:37<00:51, 4619.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 176843/414113 [00:37<00:50, 4660.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 177320/414113 [00:37<00:50, 4692.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 177794/414113 [00:38<00:50, 4705.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 178266/414113 [00:38<00:50, 4684.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 178735/414113 [00:38<00:50, 4672.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179206/414113 [00:38<00:50, 4682.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179681/414113 [00:38<00:49, 4702.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 180152/414113 [00:38<00:49, 4701.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 180623/414113 [00:38<00:49, 4671.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 181098/414113 [00:38<00:49, 4693.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 181568/414113 [00:38<00:49, 4691.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182038/414113 [00:38<00:49, 4683.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182507/414113 [00:39<01:32, 2494.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182987/414113 [00:39<01:19, 2914.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 183457/414113 [00:39<01:10, 3288.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 183942/414113 [00:39<01:03, 3639.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 184430/414113 [00:39<00:58, 3939.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 184898/414113 [00:39<00:55, 4135.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 185390/414113 [00:39<00:52, 4341.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 185859/414113 [00:40<00:51, 4417.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 186337/414113 [00:40<00:50, 4519.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 186819/414113 [00:40<00:49, 4603.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 187293/414113 [00:40<00:48, 4642.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 187782/414113 [00:40<00:48, 4712.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 188260/414113 [00:40<00:47, 4715.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 188737/414113 [00:40<00:47, 4700.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 189211/414113 [00:40<00:47, 4692.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 189684/414113 [00:40<00:47, 4700.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 190159/414113 [00:40<00:47, 4715.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 190632/414113 [00:41<00:47, 4711.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 191104/414113 [00:41<00:47, 4685.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 191578/414113 [00:41<00:47, 4701.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 192049/414113 [00:41<00:47, 4682.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 192530/414113 [00:41<00:46, 4718.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193003/414113 [00:41<00:47, 4692.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193477/414113 [00:41<00:46, 4704.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193950/414113 [00:41<00:46, 4710.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 194423/414113 [00:41<00:46, 4714.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 194895/414113 [00:41<00:46, 4689.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 195379/414113 [00:42<00:46, 4732.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 195854/414113 [00:42<00:46, 4736.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 196328/414113 [00:42<00:46, 4729.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 196802/414113 [00:42<00:46, 4692.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197276/414113 [00:42<00:46, 4704.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197755/414113 [00:42<00:45, 4729.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 198229/414113 [00:42<00:45, 4724.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 198702/414113 [00:42<00:46, 4644.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 199167/414113 [00:42<00:48, 4433.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 199644/414113 [00:42<00:47, 4528.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 200109/414113 [00:43<00:46, 4562.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 200584/414113 [00:43<00:46, 4617.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 201064/414113 [00:43<00:45, 4667.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 201561/414113 [00:43<00:44, 4751.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202038/414113 [00:43<00:44, 4746.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202514/414113 [00:43<00:44, 4730.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202988/414113 [00:43<00:45, 4688.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 203458/414113 [00:43<00:44, 4683.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 203930/414113 [00:43<00:44, 4691.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 204406/414113 [00:43<00:44, 4709.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 204892/414113 [00:44<00:44, 4751.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 205368/414113 [00:44<00:44, 4687.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 205847/414113 [00:44<00:44, 4715.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206322/414113 [00:44<00:43, 4724.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206802/414113 [00:44<00:43, 4744.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 207285/414113 [00:44<00:43, 4767.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 207762/414113 [00:44<00:43, 4761.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208239/414113 [00:44<00:43, 4755.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208718/414113 [00:44<00:43, 4763.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 209195/414113 [00:44<00:43, 4712.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 209669/414113 [00:45<00:43, 4718.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210141/414113 [00:45<00:43, 4713.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210625/414113 [00:45<00:42, 4749.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 211101/414113 [00:45<00:42, 4741.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 211576/414113 [00:45<00:42, 4737.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 212055/414113 [00:45<00:42, 4751.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 212532/414113 [00:45<00:42, 4754.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 213010/414113 [00:45<00:42, 4759.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 213491/414113 [00:45<00:42, 4774.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 213969/414113 [00:45<00:41, 4769.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214451/414113 [00:46<00:41, 4782.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214931/414113 [00:46<00:41, 4787.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215410/414113 [00:46<00:41, 4777.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215888/414113 [00:46<00:41, 4752.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 216364/414113 [00:46<00:42, 4643.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 216839/414113 [00:46<00:42, 4674.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 217321/414113 [00:46<00:41, 4717.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 217811/414113 [00:46<00:41, 4768.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 218299/414113 [00:46<00:40, 4799.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 218780/414113 [00:46<00:40, 4781.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 219259/414113 [00:47<00:41, 4726.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 219732/414113 [00:47<00:42, 4619.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220195/414113 [00:47<00:42, 4518.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220648/414113 [00:47<00:43, 4496.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 221099/414113 [00:47<00:43, 4417.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 221582/414113 [00:47<00:42, 4533.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 222038/414113 [00:47<00:42, 4539.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 222494/414113 [00:47<00:42, 4542.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 222977/414113 [00:47<00:41, 4623.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 223441/414113 [00:48<00:41, 4550.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 223897/414113 [00:48<00:41, 4532.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 224372/414113 [00:48<00:41, 4593.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 224832/414113 [00:48<00:41, 4592.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 225301/414113 [00:48<00:40, 4619.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 225777/414113 [00:48<00:40, 4658.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 226250/414113 [00:48<00:40, 4679.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 226726/414113 [00:48<00:39, 4702.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 227200/414113 [00:48<00:39, 4713.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 227676/414113 [00:48<00:39, 4727.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 228167/414113 [00:49<00:38, 4779.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 228646/414113 [00:49<00:38, 4780.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 229130/414113 [00:49<00:38, 4796.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 229610/414113 [00:49<00:38, 4767.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230089/414113 [00:49<00:38, 4773.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230567/414113 [00:49<00:38, 4725.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231040/414113 [00:49<00:39, 4662.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231514/414113 [00:49<00:38, 4684.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231985/414113 [00:49<00:38, 4691.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 232455/414113 [00:49<00:38, 4674.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 232923/414113 [00:50<00:39, 4642.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 233404/414113 [00:50<00:38, 4691.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 233880/414113 [00:50<00:38, 4711.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 234352/414113 [00:50<00:38, 4704.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 234823/414113 [00:50<00:38, 4700.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235295/414113 [00:50<00:37, 4705.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235781/414113 [00:50<00:37, 4748.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 236257/414113 [00:50<00:37, 4729.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 236731/414113 [00:50<00:37, 4701.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 237208/414113 [00:50<00:37, 4719.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 237681/414113 [00:51<00:37, 4703.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 238152/414113 [00:51<00:37, 4679.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 238620/414113 [00:51<00:37, 4660.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239096/414113 [00:51<00:37, 4688.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239565/414113 [00:51<00:37, 4683.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240036/414113 [00:51<00:37, 4691.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240509/414113 [00:51<00:36, 4700.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240980/414113 [00:51<00:37, 4673.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 241448/414113 [00:51<00:37, 4661.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 241915/414113 [00:51<00:36, 4661.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 242387/414113 [00:52<00:36, 4676.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 242864/414113 [00:52<00:36, 4701.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 243341/414113 [00:52<00:36, 4721.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 243817/414113 [00:52<00:36, 4729.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 244291/414113 [00:52<00:35, 4727.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 244773/414113 [00:52<00:35, 4753.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245249/414113 [00:52<00:35, 4754.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245725/414113 [00:52<00:35, 4697.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 246202/414113 [00:52<00:35, 4717.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 246683/414113 [00:52<00:35, 4742.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 247166/414113 [00:53<00:35, 4767.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 247655/414113 [00:53<00:34, 4803.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 248136/414113 [00:53<00:34, 4789.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 248616/414113 [00:53<00:35, 4724.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249095/414113 [00:53<00:34, 4743.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249570/414113 [00:53<00:34, 4732.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 250051/414113 [00:53<00:34, 4755.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 250527/414113 [00:53<00:34, 4751.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251006/414113 [00:53<00:34, 4760.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251492/414113 [00:53<00:33, 4789.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251977/414113 [00:54<00:33, 4805.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 252458/414113 [00:54<00:33, 4806.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 252939/414113 [00:54<00:33, 4786.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 253418/414113 [00:54<00:35, 4509.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 253895/414113 [00:54<00:34, 4583.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 254359/414113 [00:54<00:34, 4599.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 254829/414113 [00:54<00:34, 4628.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 255294/414113 [00:54<00:34, 4627.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 255758/414113 [00:54<00:34, 4599.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256229/414113 [00:54<00:34, 4630.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256707/414113 [00:55<00:33, 4672.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 257186/414113 [00:55<00:33, 4704.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 257659/414113 [00:55<00:33, 4711.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 258140/414113 [00:55<00:32, 4738.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 258616/414113 [00:55<00:32, 4743.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 259091/414113 [00:55<00:32, 4722.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 259576/414113 [00:55<00:32, 4759.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 260053/414113 [00:55<00:32, 4733.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 260533/414113 [00:55<00:32, 4752.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261009/414113 [00:55<00:32, 4736.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261487/414113 [00:56<00:32, 4747.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261962/414113 [00:56<00:32, 4739.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 262437/414113 [00:56<00:32, 4739.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 262911/414113 [00:56<00:31, 4736.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 263385/414113 [00:56<00:32, 4682.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 263854/414113 [00:56<00:32, 4683.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 264323/414113 [00:56<00:32, 4675.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 264791/414113 [00:56<00:32, 4637.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 265255/414113 [00:56<00:32, 4625.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 265718/414113 [00:57<00:32, 4601.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266179/414113 [00:57<00:32, 4585.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266654/414113 [00:57<00:31, 4631.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 267118/414113 [00:57<00:31, 4620.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 267598/414113 [00:57<00:31, 4670.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 268066/414113 [00:57<00:31, 4671.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 268542/414113 [00:57<00:30, 4697.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 269021/414113 [00:57<00:30, 4722.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 269494/414113 [00:57<00:30, 4717.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 269981/414113 [00:57<00:30, 4759.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270458/414113 [00:58<00:30, 4717.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270936/414113 [00:58<00:30, 4733.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 271410/414113 [00:58<00:30, 4683.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 271901/414113 [00:58<00:29, 4748.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 272380/414113 [00:58<00:29, 4758.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 272859/414113 [00:58<00:29, 4764.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 273336/414113 [00:58<00:29, 4757.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 273819/414113 [00:58<00:29, 4777.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 274297/414113 [00:58<00:29, 4737.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 274784/414113 [00:58<00:29, 4773.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 275262/414113 [00:59<00:29, 4754.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 275744/414113 [00:59<00:29, 4770.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 276222/414113 [00:59<00:29, 4745.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 276704/414113 [00:59<00:28, 4767.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 277186/414113 [00:59<00:28, 4782.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 277665/414113 [00:59<00:28, 4768.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 278147/414113 [00:59<00:28, 4781.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 278630/414113 [00:59<00:28, 4794.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 279114/414113 [00:59<00:28, 4808.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 279595/414113 [00:59<00:28, 4804.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280092/414113 [01:00<00:27, 4850.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280579/414113 [01:00<00:27, 4854.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 281065/414113 [01:00<00:27, 4847.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 281550/414113 [01:00<00:27, 4831.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 282043/414113 [01:00<00:27, 4858.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 282529/414113 [01:00<00:27, 4857.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 283019/414113 [01:00<00:26, 4869.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 283508/414113 [01:00<00:26, 4873.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 283998/414113 [01:00<00:26, 4879.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 284486/414113 [01:00<00:26, 4865.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 284976/414113 [01:01<00:26, 4874.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285464/414113 [01:01<00:26, 4849.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285949/414113 [01:01<00:26, 4844.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 286434/414113 [01:01<00:26, 4804.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 286915/414113 [01:01<00:26, 4781.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 287405/414113 [01:01<00:26, 4813.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 287889/414113 [01:01<00:26, 4821.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288380/414113 [01:01<00:25, 4845.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288874/414113 [01:01<00:25, 4873.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 289369/414113 [01:01<00:25, 4894.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 289867/414113 [01:02<00:25, 4919.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 290362/414113 [01:02<00:25, 4927.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 290855/414113 [01:02<00:25, 4907.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 291349/414113 [01:02<00:24, 4916.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 291841/414113 [01:02<00:24, 4904.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 292338/414113 [01:02<00:24, 4922.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 292831/414113 [01:02<00:24, 4924.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293337/414113 [01:02<00:24, 4962.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293834/414113 [01:02<00:24, 4925.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 294327/414113 [01:02<00:24, 4917.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 294819/414113 [01:03<00:24, 4842.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295304/414113 [01:03<00:24, 4818.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295787/414113 [01:03<00:24, 4803.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 296268/414113 [01:03<00:24, 4789.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 296748/414113 [01:03<00:24, 4781.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 297228/414113 [01:03<00:24, 4786.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 297707/414113 [01:03<00:24, 4744.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298182/414113 [01:03<00:24, 4745.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298657/414113 [01:03<00:24, 4743.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 299132/414113 [01:03<00:24, 4719.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 299620/414113 [01:04<00:24, 4765.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 300097/414113 [01:04<00:23, 4758.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 300578/414113 [01:04<00:23, 4772.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 301056/414113 [01:04<00:24, 4537.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 301534/414113 [01:04<00:24, 4607.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302013/414113 [01:04<00:24, 4660.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302496/414113 [01:04<00:23, 4709.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302975/414113 [01:04<00:23, 4732.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303465/414113 [01:04<00:23, 4779.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303944/414113 [01:04<00:23, 4734.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 304419/414113 [01:05<00:23, 4738.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 304895/414113 [01:05<00:23, 4742.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 305370/414113 [01:05<00:23, 4707.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 305842/414113 [01:05<00:23, 4692.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 306317/414113 [01:05<00:22, 4708.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 306789/414113 [01:05<00:23, 4653.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307263/414113 [01:05<00:22, 4659.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307740/414113 [01:05<00:22, 4690.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 308221/414113 [01:05<00:22, 4723.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 308697/414113 [01:05<00:22, 4731.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309171/414113 [01:06<00:22, 4727.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309661/414113 [01:06<00:21, 4776.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 310153/414113 [01:06<00:21, 4818.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 310636/414113 [01:06<00:21, 4812.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311118/414113 [01:06<00:21, 4796.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311598/414113 [01:06<00:21, 4787.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 312077/414113 [01:06<00:21, 4771.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 312565/414113 [01:06<00:21, 4802.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 313046/414113 [01:06<00:21, 4777.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 313525/414113 [01:06<00:21, 4779.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314004/414113 [01:07<00:21, 4694.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314489/414113 [01:07<00:21, 4739.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314971/414113 [01:07<00:20, 4761.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 315464/414113 [01:07<00:20, 4810.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 315954/414113 [01:07<00:20, 4835.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 316449/414113 [01:07<00:20, 4868.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 316940/414113 [01:07<00:19, 4879.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 317441/414113 [01:07<00:19, 4918.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 317933/414113 [01:07<00:19, 4900.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 318424/414113 [01:08<00:19, 4876.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 318919/414113 [01:08<00:19, 4895.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319409/414113 [01:08<00:19, 4874.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319897/414113 [01:08<00:19, 4869.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 320391/414113 [01:08<00:19, 4889.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 320888/414113 [01:08<00:18, 4911.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 321385/414113 [01:08<00:18, 4928.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 321880/414113 [01:08<00:18, 4931.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 322374/414113 [01:08<00:18, 4915.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 322866/414113 [01:08<00:18, 4902.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 323362/414113 [01:09<00:18, 4919.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 323854/414113 [01:09<00:18, 4880.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 324343/414113 [01:09<00:18, 4841.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 324841/414113 [01:09<00:18, 4881.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 325330/414113 [01:09<00:18, 4879.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 325825/414113 [01:09<00:18, 4898.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 326315/414113 [01:09<00:17, 4887.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 326804/414113 [01:09<00:17, 4873.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 327300/414113 [01:09<00:17, 4898.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 327790/414113 [01:09<00:17, 4873.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 328278/414113 [01:10<00:17, 4842.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 328763/414113 [01:10<00:17, 4836.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 329247/414113 [01:10<00:17, 4813.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 329729/414113 [01:10<00:17, 4810.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 330211/414113 [01:10<00:17, 4802.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 330692/414113 [01:10<00:17, 4757.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 331168/414113 [01:10<00:17, 4737.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 331642/414113 [01:10<00:17, 4736.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 332127/414113 [01:10<00:17, 4769.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 332605/414113 [01:10<00:17, 4767.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 333082/414113 [01:11<00:34, 2338.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 333560/414113 [01:11<00:29, 2761.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 334043/414113 [01:11<00:25, 3167.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 334530/414113 [01:11<00:22, 3538.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335008/414113 [01:11<00:20, 3835.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335487/414113 [01:11<00:19, 4079.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335963/414113 [01:11<00:18, 4261.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 336436/414113 [01:12<00:17, 4389.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 336914/414113 [01:12<00:17, 4500.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 337385/414113 [01:12<00:16, 4556.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 337863/414113 [01:12<00:16, 4618.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 338339/414113 [01:12<00:16, 4657.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 338815/414113 [01:12<00:16, 4684.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 339291/414113 [01:12<00:15, 4705.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 339766/414113 [01:12<00:15, 4715.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 340247/414113 [01:12<00:15, 4742.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 340728/414113 [01:12<00:15, 4761.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 341210/414113 [01:13<00:15, 4777.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 341689/414113 [01:13<00:15, 4759.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 342176/414113 [01:13<00:15, 4790.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 342661/414113 [01:13<00:14, 4806.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 343148/414113 [01:13<00:14, 4822.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 343631/414113 [01:13<00:14, 4820.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 344119/414113 [01:13<00:14, 4836.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 344603/414113 [01:13<00:14, 4822.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 345091/414113 [01:13<00:14, 4839.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 345576/414113 [01:13<00:14, 4815.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 346068/414113 [01:14<00:14, 4844.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 346553/414113 [01:14<00:13, 4832.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347037/414113 [01:14<00:13, 4824.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347520/414113 [01:14<00:13, 4788.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347999/414113 [01:14<00:13, 4777.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 348477/414113 [01:14<00:13, 4744.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 348961/414113 [01:14<00:13, 4771.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 349441/414113 [01:14<00:13, 4779.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 349919/414113 [01:14<00:13, 4747.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 350410/414113 [01:14<00:13, 4794.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 350902/414113 [01:15<00:13, 4831.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 351386/414113 [01:15<00:12, 4831.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 351870/414113 [01:15<00:12, 4831.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 352355/414113 [01:15<00:12, 4834.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 352839/414113 [01:15<00:12, 4831.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353323/414113 [01:15<00:12, 4787.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353805/414113 [01:15<00:12, 4794.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 354294/414113 [01:15<00:12, 4821.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 354792/414113 [01:15<00:12, 4866.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 355282/414113 [01:15<00:12, 4874.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 355770/414113 [01:16<00:11, 4869.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 356258/414113 [01:16<00:12, 4777.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 356737/414113 [01:16<00:12, 4758.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 357214/414113 [01:16<00:12, 4721.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 357696/414113 [01:16<00:11, 4749.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 358175/414113 [01:16<00:11, 4759.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 358656/414113 [01:16<00:11, 4772.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359150/414113 [01:16<00:11, 4819.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359633/414113 [01:16<00:11, 4787.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 360123/414113 [01:17<00:11, 4818.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 360605/414113 [01:17<00:11, 4593.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 361085/414113 [01:17<00:11, 4652.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 361559/414113 [01:17<00:11, 4675.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 362035/414113 [01:17<00:11, 4699.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 362512/414113 [01:17<00:10, 4717.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 362985/414113 [01:17<00:10, 4700.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363456/414113 [01:17<00:10, 4683.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363932/414113 [01:17<00:10, 4704.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 364414/414113 [01:17<00:10, 4738.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 364896/414113 [01:18<00:10, 4762.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365386/414113 [01:18<00:10, 4801.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365867/414113 [01:18<00:10, 4801.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 366348/414113 [01:18<00:09, 4800.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 366834/414113 [01:18<00:09, 4816.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 367316/414113 [01:18<00:09, 4795.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 367801/414113 [01:18<00:09, 4809.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 368284/414113 [01:18<00:09, 4814.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 368766/414113 [01:18<00:09, 4814.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 369258/414113 [01:18<00:09, 4844.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 369743/414113 [01:19<00:09, 4801.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 370227/414113 [01:19<00:09, 4812.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 370709/414113 [01:19<00:09, 4759.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371186/414113 [01:19<00:09, 4754.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371662/414113 [01:19<00:08, 4731.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 372142/414113 [01:19<00:08, 4749.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 372618/414113 [01:19<00:08, 4741.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 373093/414113 [01:19<00:08, 4726.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 373566/414113 [01:19<00:08, 4665.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 374033/414113 [01:19<00:08, 4665.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 374510/414113 [01:20<00:08, 4694.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 374981/414113 [01:20<00:08, 4696.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 375460/414113 [01:20<00:08, 4722.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 375933/414113 [01:20<00:08, 4582.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376421/414113 [01:20<00:08, 4668.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376894/414113 [01:20<00:07, 4684.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 377365/414113 [01:20<00:07, 4690.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 377854/414113 [01:20<00:07, 4747.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 378331/414113 [01:20<00:07, 4751.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 378816/414113 [01:20<00:07, 4780.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 379295/414113 [01:21<00:07, 4774.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 379775/414113 [01:21<00:07, 4781.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 380254/414113 [01:21<00:07, 4776.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 380746/414113 [01:21<00:06, 4818.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 381234/414113 [01:21<00:06, 4834.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 381718/414113 [01:21<00:06, 4814.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382213/414113 [01:21<00:06, 4851.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382701/414113 [01:21<00:06, 4858.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 383187/414113 [01:21<00:06, 4710.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 383680/414113 [01:21<00:06, 4771.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 384159/414113 [01:22<00:06, 4759.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 384636/414113 [01:22<00:06, 4752.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 385125/414113 [01:22<00:06, 4791.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 385608/414113 [01:22<00:05, 4801.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 386089/414113 [01:22<00:05, 4802.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 386571/414113 [01:22<00:05, 4806.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 387059/414113 [01:22<00:05, 4825.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 387550/414113 [01:22<00:05, 4848.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 388042/414113 [01:22<00:05, 4869.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 388530/414113 [01:22<00:05, 4853.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 389029/414113 [01:23<00:05, 4893.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 389519/414113 [01:23<00:05, 4869.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390007/414113 [01:23<00:04, 4840.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390492/414113 [01:23<00:04, 4751.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390968/414113 [01:23<00:04, 4707.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 391449/414113 [01:23<00:04, 4736.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 391932/414113 [01:23<00:04, 4760.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 392415/414113 [01:23<00:04, 4780.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 392900/414113 [01:23<00:04, 4798.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 393381/414113 [01:23<00:04, 4770.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 393867/414113 [01:24<00:04, 4795.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 394356/414113 [01:24<00:04, 4822.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 394839/414113 [01:24<00:04, 4806.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 395320/414113 [01:24<00:03, 4780.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 395799/414113 [01:24<00:03, 4769.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 396290/414113 [01:24<00:03, 4809.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 396772/414113 [01:24<00:03, 4780.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 397261/414113 [01:24<00:03, 4811.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 397743/414113 [01:24<00:03, 4797.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 398226/414113 [01:25<00:03, 4805.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 398707/414113 [01:25<00:03, 4792.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 399187/414113 [01:25<00:03, 4772.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 399665/414113 [01:25<00:03, 4724.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400148/414113 [01:25<00:02, 4754.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400634/414113 [01:25<00:02, 4785.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 401113/414113 [01:25<00:02, 4765.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 401590/414113 [01:25<00:02, 4760.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 402070/414113 [01:25<00:02, 4770.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 402548/414113 [01:25<00:02, 4745.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 403038/414113 [01:26<00:02, 4789.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 403518/414113 [01:26<00:02, 4774.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404000/414113 [01:26<00:02, 4785.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404486/414113 [01:26<00:02, 4805.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404967/414113 [01:26<00:01, 4773.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 405445/414113 [01:26<00:01, 4773.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 405923/414113 [01:26<00:01, 4748.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 406403/414113 [01:26<00:01, 4763.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 406896/414113 [01:26<00:01, 4811.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 407380/414113 [01:26<00:01, 4818.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 407869/414113 [01:27<00:01, 4837.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 408353/414113 [01:27<00:01, 4832.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 408844/414113 [01:27<00:01, 4853.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 409331/414113 [01:27<00:00, 4856.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 409817/414113 [01:27<00:00, 4840.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 410317/414113 [01:27<00:00, 4885.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 410806/414113 [01:27<00:00, 4845.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 411292/414113 [01:27<00:00, 4848.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 411777/414113 [01:27<00:00, 4791.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 412259/414113 [01:27<00:00, 4799.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 412744/414113 [01:28<00:00, 4814.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 413228/414113 [01:28<00:00, 4820.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 413722/414113 [01:28<00:00, 4852.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 414113/414113 [01:28<00:00, 4689.09it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.88s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 32          # batch size\n",
    "vocab_threshold = 10        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 256           # dimensionality of image and word embeddings\n",
    "hidden_size = 256          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(encoder.embed.parameters()) + list(decoder.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/12942], Loss: 4.0774, Perplexity: 58.99116\n",
      "Epoch [1/3], Step [200/12942], Loss: 3.7575, Perplexity: 42.84181\n",
      "Epoch [1/3], Step [300/12942], Loss: 3.6129, Perplexity: 37.07302\n",
      "Epoch [1/3], Step [400/12942], Loss: 3.5801, Perplexity: 35.8777\n",
      "Epoch [1/3], Step [500/12942], Loss: 3.4739, Perplexity: 32.26359\n",
      "Epoch [1/3], Step [600/12942], Loss: 3.2448, Perplexity: 25.6559\n",
      "Epoch [1/3], Step [700/12942], Loss: 3.5064, Perplexity: 33.3291\n",
      "Epoch [1/3], Step [800/12942], Loss: 3.0465, Perplexity: 21.04110\n",
      "Epoch [1/3], Step [900/12942], Loss: 3.0268, Perplexity: 20.6309\n",
      "Epoch [1/3], Step [1000/12942], Loss: 2.8649, Perplexity: 17.5478\n",
      "Epoch [1/3], Step [1100/12942], Loss: 2.7293, Perplexity: 15.3225\n",
      "Epoch [1/3], Step [1200/12942], Loss: 2.8633, Perplexity: 17.5194\n",
      "Epoch [1/3], Step [1300/12942], Loss: 3.1359, Perplexity: 23.0085\n",
      "Epoch [1/3], Step [1400/12942], Loss: 2.7021, Perplexity: 14.9111\n",
      "Epoch [1/3], Step [1500/12942], Loss: 2.9178, Perplexity: 18.5012\n",
      "Epoch [1/3], Step [1600/12942], Loss: 2.9295, Perplexity: 18.7187\n",
      "Epoch [1/3], Step [1700/12942], Loss: 2.7139, Perplexity: 15.0879\n",
      "Epoch [1/3], Step [1800/12942], Loss: 2.7771, Perplexity: 16.07304\n",
      "Epoch [1/3], Step [1900/12942], Loss: 2.4793, Perplexity: 11.9332\n",
      "Epoch [1/3], Step [2000/12942], Loss: 3.5343, Perplexity: 34.2708\n",
      "Epoch [1/3], Step [2100/12942], Loss: 2.9844, Perplexity: 19.7745\n",
      "Epoch [1/3], Step [2200/12942], Loss: 2.6593, Perplexity: 14.2868\n",
      "Epoch [1/3], Step [2300/12942], Loss: 2.5271, Perplexity: 12.5172\n",
      "Epoch [1/3], Step [2400/12942], Loss: 2.1127, Perplexity: 8.27018\n",
      "Epoch [1/3], Step [2500/12942], Loss: 2.6294, Perplexity: 13.8654\n",
      "Epoch [1/3], Step [2600/12942], Loss: 2.4409, Perplexity: 11.4838\n",
      "Epoch [1/3], Step [2700/12942], Loss: 3.0036, Perplexity: 20.1573\n",
      "Epoch [1/3], Step [2800/12942], Loss: 2.2405, Perplexity: 9.39816\n",
      "Epoch [1/3], Step [2900/12942], Loss: 2.4378, Perplexity: 11.4477\n",
      "Epoch [1/3], Step [3000/12942], Loss: 2.9758, Perplexity: 19.6050\n",
      "Epoch [1/3], Step [3100/12942], Loss: 2.7341, Perplexity: 15.3960\n",
      "Epoch [1/3], Step [3200/12942], Loss: 2.2087, Perplexity: 9.10388\n",
      "Epoch [1/3], Step [3300/12942], Loss: 2.4224, Perplexity: 11.2727\n",
      "Epoch [1/3], Step [3400/12942], Loss: 2.3664, Perplexity: 10.6592\n",
      "Epoch [1/3], Step [3500/12942], Loss: 2.5529, Perplexity: 12.8437\n",
      "Epoch [1/3], Step [3600/12942], Loss: 2.4928, Perplexity: 12.0952\n",
      "Epoch [1/3], Step [3700/12942], Loss: 2.4640, Perplexity: 11.7513\n",
      "Epoch [1/3], Step [3800/12942], Loss: 2.2665, Perplexity: 9.64544\n",
      "Epoch [1/3], Step [3900/12942], Loss: 2.1801, Perplexity: 8.84687\n",
      "Epoch [1/3], Step [4000/12942], Loss: 2.3971, Perplexity: 10.9912\n",
      "Epoch [1/3], Step [4100/12942], Loss: 2.2856, Perplexity: 9.83179\n",
      "Epoch [1/3], Step [4200/12942], Loss: 2.4652, Perplexity: 11.7659\n",
      "Epoch [1/3], Step [4300/12942], Loss: 2.4061, Perplexity: 11.0906\n",
      "Epoch [1/3], Step [4400/12942], Loss: 2.2907, Perplexity: 9.88188\n",
      "Epoch [1/3], Step [4500/12942], Loss: 2.8067, Perplexity: 16.5546\n",
      "Epoch [1/3], Step [4600/12942], Loss: 2.4250, Perplexity: 11.3021\n",
      "Epoch [1/3], Step [4700/12942], Loss: 2.2938, Perplexity: 9.91270\n",
      "Epoch [1/3], Step [4800/12942], Loss: 2.4231, Perplexity: 11.28135\n",
      "Epoch [1/3], Step [4900/12942], Loss: 2.3385, Perplexity: 10.3660\n",
      "Epoch [1/3], Step [5000/12942], Loss: 3.1966, Perplexity: 24.4488\n",
      "Epoch [1/3], Step [5100/12942], Loss: 2.4330, Perplexity: 11.39323\n",
      "Epoch [1/3], Step [5200/12942], Loss: 2.3140, Perplexity: 10.1148\n",
      "Epoch [1/3], Step [5300/12942], Loss: 2.3534, Perplexity: 10.5216\n",
      "Epoch [1/3], Step [5400/12942], Loss: 3.3137, Perplexity: 27.4868\n",
      "Epoch [1/3], Step [5500/12942], Loss: 2.0798, Perplexity: 8.00315\n",
      "Epoch [1/3], Step [5600/12942], Loss: 2.2986, Perplexity: 9.96026\n",
      "Epoch [1/3], Step [5700/12942], Loss: 2.3097, Perplexity: 10.0716\n",
      "Epoch [1/3], Step [5800/12942], Loss: 2.4309, Perplexity: 11.3686\n",
      "Epoch [1/3], Step [5900/12942], Loss: 2.2596, Perplexity: 9.57895\n",
      "Epoch [1/3], Step [6000/12942], Loss: 2.4381, Perplexity: 11.4508\n",
      "Epoch [1/3], Step [6100/12942], Loss: 2.7609, Perplexity: 15.8142\n",
      "Epoch [1/3], Step [6200/12942], Loss: 2.1076, Perplexity: 8.22819\n",
      "Epoch [1/3], Step [6300/12942], Loss: 2.4671, Perplexity: 11.7885\n",
      "Epoch [1/3], Step [6400/12942], Loss: 1.8965, Perplexity: 6.66282\n",
      "Epoch [1/3], Step [6500/12942], Loss: 3.0181, Perplexity: 20.4523\n",
      "Epoch [1/3], Step [6600/12942], Loss: 2.4521, Perplexity: 11.6125\n",
      "Epoch [1/3], Step [6700/12942], Loss: 2.1237, Perplexity: 8.36234\n",
      "Epoch [1/3], Step [6800/12942], Loss: 2.7193, Perplexity: 15.1697\n",
      "Epoch [1/3], Step [6900/12942], Loss: 2.1584, Perplexity: 8.65768\n",
      "Epoch [1/3], Step [7000/12942], Loss: 2.0735, Perplexity: 7.95287\n",
      "Epoch [1/3], Step [7100/12942], Loss: 2.1813, Perplexity: 8.85788\n",
      "Epoch [1/3], Step [7200/12942], Loss: 2.0948, Perplexity: 8.12409\n",
      "Epoch [1/3], Step [7300/12942], Loss: 2.2827, Perplexity: 9.80287\n",
      "Epoch [1/3], Step [7400/12942], Loss: 2.0604, Perplexity: 7.84928\n",
      "Epoch [1/3], Step [7500/12942], Loss: 2.3078, Perplexity: 10.0518\n",
      "Epoch [1/3], Step [7600/12942], Loss: 2.2603, Perplexity: 9.58611\n",
      "Epoch [1/3], Step [7700/12942], Loss: 2.5977, Perplexity: 13.4329\n",
      "Epoch [1/3], Step [7800/12942], Loss: 2.3811, Perplexity: 10.8170\n",
      "Epoch [1/3], Step [7900/12942], Loss: 2.3426, Perplexity: 10.4079\n",
      "Epoch [1/3], Step [8000/12942], Loss: 2.1716, Perplexity: 8.77211\n",
      "Epoch [1/3], Step [8100/12942], Loss: 2.3103, Perplexity: 10.0772\n",
      "Epoch [1/3], Step [8200/12942], Loss: 2.1683, Perplexity: 8.74307\n",
      "Epoch [1/3], Step [8300/12942], Loss: 2.3367, Perplexity: 10.3469\n",
      "Epoch [1/3], Step [8400/12942], Loss: 2.3914, Perplexity: 10.9286\n",
      "Epoch [1/3], Step [8500/12942], Loss: 2.6535, Perplexity: 14.2037\n",
      "Epoch [1/3], Step [8600/12942], Loss: 2.5853, Perplexity: 13.2675\n",
      "Epoch [1/3], Step [8700/12942], Loss: 2.0639, Perplexity: 7.87665\n",
      "Epoch [1/3], Step [8800/12942], Loss: 2.4467, Perplexity: 11.5499\n",
      "Epoch [1/3], Step [8900/12942], Loss: 2.3225, Perplexity: 10.2010\n",
      "Epoch [1/3], Step [9000/12942], Loss: 2.2992, Perplexity: 9.96621\n",
      "Epoch [1/3], Step [9100/12942], Loss: 2.3235, Perplexity: 10.2114\n",
      "Epoch [1/3], Step [9200/12942], Loss: 1.9797, Perplexity: 7.24071\n",
      "Epoch [1/3], Step [9300/12942], Loss: 2.1074, Perplexity: 8.22663\n",
      "Epoch [1/3], Step [9400/12942], Loss: 2.1772, Perplexity: 8.82204\n",
      "Epoch [1/3], Step [9500/12942], Loss: 2.2695, Perplexity: 9.67455\n",
      "Epoch [1/3], Step [9600/12942], Loss: 2.1741, Perplexity: 8.79399\n",
      "Epoch [1/3], Step [9700/12942], Loss: 1.9954, Perplexity: 7.35516\n",
      "Epoch [1/3], Step [9800/12942], Loss: 2.4028, Perplexity: 11.0537\n",
      "Epoch [1/3], Step [9900/12942], Loss: 2.2305, Perplexity: 9.30469\n",
      "Epoch [1/3], Step [10000/12942], Loss: 2.1906, Perplexity: 8.9409\n",
      "Epoch [1/3], Step [10100/12942], Loss: 2.5135, Perplexity: 12.3483\n",
      "Epoch [1/3], Step [10200/12942], Loss: 2.1954, Perplexity: 8.98336\n",
      "Epoch [1/3], Step [10300/12942], Loss: 1.8868, Perplexity: 6.59806\n",
      "Epoch [1/3], Step [10400/12942], Loss: 2.4422, Perplexity: 11.4983\n",
      "Epoch [1/3], Step [10500/12942], Loss: 2.1728, Perplexity: 8.78260\n",
      "Epoch [1/3], Step [10600/12942], Loss: 1.9679, Perplexity: 7.15548\n",
      "Epoch [1/3], Step [10700/12942], Loss: 2.0758, Perplexity: 7.97124\n",
      "Epoch [1/3], Step [10800/12942], Loss: 2.5802, Perplexity: 13.1997\n",
      "Epoch [1/3], Step [10900/12942], Loss: 2.0408, Perplexity: 7.69710\n",
      "Epoch [1/3], Step [11000/12942], Loss: 2.0299, Perplexity: 7.61311\n",
      "Epoch [1/3], Step [11100/12942], Loss: 2.4548, Perplexity: 11.6436\n",
      "Epoch [1/3], Step [11200/12942], Loss: 2.0717, Perplexity: 7.93878\n",
      "Epoch [1/3], Step [11300/12942], Loss: 2.2713, Perplexity: 9.69171\n",
      "Epoch [1/3], Step [11400/12942], Loss: 2.0936, Perplexity: 8.11432\n",
      "Epoch [1/3], Step [11500/12942], Loss: 2.1807, Perplexity: 8.85263\n",
      "Epoch [1/3], Step [11600/12942], Loss: 2.2597, Perplexity: 9.58066\n",
      "Epoch [1/3], Step [11700/12942], Loss: 2.3184, Perplexity: 10.1596\n",
      "Epoch [1/3], Step [11800/12942], Loss: 2.1309, Perplexity: 8.42241\n",
      "Epoch [1/3], Step [11900/12942], Loss: 2.1936, Perplexity: 8.96706\n",
      "Epoch [1/3], Step [12000/12942], Loss: 2.0419, Perplexity: 7.70563\n",
      "Epoch [1/3], Step [12100/12942], Loss: 2.1733, Perplexity: 8.78752\n",
      "Epoch [1/3], Step [12200/12942], Loss: 3.0077, Perplexity: 20.2408\n",
      "Epoch [1/3], Step [12300/12942], Loss: 2.2734, Perplexity: 9.71282\n",
      "Epoch [1/3], Step [12400/12942], Loss: 2.0393, Perplexity: 7.68495\n",
      "Epoch [1/3], Step [12500/12942], Loss: 1.9722, Perplexity: 7.18676\n",
      "Epoch [1/3], Step [12600/12942], Loss: 1.9978, Perplexity: 7.37294\n",
      "Epoch [1/3], Step [12700/12942], Loss: 1.9761, Perplexity: 7.21438\n",
      "Epoch [1/3], Step [12800/12942], Loss: 2.1074, Perplexity: 8.22708\n",
      "Epoch [1/3], Step [12900/12942], Loss: 2.1152, Perplexity: 8.29124\n",
      "Epoch [2/3], Step [100/12942], Loss: 2.0849, Perplexity: 8.0436249\n",
      "Epoch [2/3], Step [200/12942], Loss: 1.9398, Perplexity: 6.95771\n",
      "Epoch [2/3], Step [300/12942], Loss: 2.0322, Perplexity: 7.63114\n",
      "Epoch [2/3], Step [400/12942], Loss: 2.6392, Perplexity: 14.0018\n",
      "Epoch [2/3], Step [500/12942], Loss: 2.1718, Perplexity: 8.77396\n",
      "Epoch [2/3], Step [600/12942], Loss: 1.7481, Perplexity: 5.74373\n",
      "Epoch [2/3], Step [700/12942], Loss: 1.9795, Perplexity: 7.23939\n",
      "Epoch [2/3], Step [800/12942], Loss: 2.0732, Perplexity: 7.95040\n",
      "Epoch [2/3], Step [900/12942], Loss: 2.2130, Perplexity: 9.14277\n",
      "Epoch [2/3], Step [1000/12942], Loss: 2.5251, Perplexity: 12.4924\n",
      "Epoch [2/3], Step [1100/12942], Loss: 2.4647, Perplexity: 11.7602\n",
      "Epoch [2/3], Step [1200/12942], Loss: 2.0035, Perplexity: 7.41500\n",
      "Epoch [2/3], Step [1300/12942], Loss: 2.0452, Perplexity: 7.73067\n",
      "Epoch [2/3], Step [1400/12942], Loss: 2.3002, Perplexity: 9.97629\n",
      "Epoch [2/3], Step [1500/12942], Loss: 2.0427, Perplexity: 7.71121\n",
      "Epoch [2/3], Step [1600/12942], Loss: 2.1655, Perplexity: 8.71928\n",
      "Epoch [2/3], Step [1700/12942], Loss: 2.1106, Perplexity: 8.25281\n",
      "Epoch [2/3], Step [1800/12942], Loss: 2.0470, Perplexity: 7.74435\n",
      "Epoch [2/3], Step [1900/12942], Loss: 2.2039, Perplexity: 9.06016\n",
      "Epoch [2/3], Step [2000/12942], Loss: 2.1236, Perplexity: 8.36121\n",
      "Epoch [2/3], Step [2100/12942], Loss: 2.1659, Perplexity: 8.72247\n",
      "Epoch [2/3], Step [2200/12942], Loss: 2.0961, Perplexity: 8.13403\n",
      "Epoch [2/3], Step [2300/12942], Loss: 1.8740, Perplexity: 6.51457\n",
      "Epoch [2/3], Step [2400/12942], Loss: 2.0910, Perplexity: 8.09322\n",
      "Epoch [2/3], Step [2500/12942], Loss: 1.9796, Perplexity: 7.24015\n",
      "Epoch [2/3], Step [2600/12942], Loss: 2.3616, Perplexity: 10.6084\n",
      "Epoch [2/3], Step [2700/12942], Loss: 2.0024, Perplexity: 7.40655\n",
      "Epoch [2/3], Step [2800/12942], Loss: 2.0046, Perplexity: 7.42342\n",
      "Epoch [2/3], Step [2900/12942], Loss: 1.9010, Perplexity: 6.69239\n",
      "Epoch [2/3], Step [3000/12942], Loss: 2.0067, Perplexity: 7.43862\n",
      "Epoch [2/3], Step [3100/12942], Loss: 2.1751, Perplexity: 8.80335\n",
      "Epoch [2/3], Step [3200/12942], Loss: 2.1209, Perplexity: 8.33847\n",
      "Epoch [2/3], Step [3300/12942], Loss: 2.0030, Perplexity: 7.41121\n",
      "Epoch [2/3], Step [3400/12942], Loss: 1.9649, Perplexity: 7.13398\n",
      "Epoch [2/3], Step [3500/12942], Loss: 2.1915, Perplexity: 8.94910\n",
      "Epoch [2/3], Step [3600/12942], Loss: 2.1682, Perplexity: 8.74251\n",
      "Epoch [2/3], Step [3700/12942], Loss: 1.9848, Perplexity: 7.27750\n",
      "Epoch [2/3], Step [3800/12942], Loss: 1.9408, Perplexity: 6.96446\n",
      "Epoch [2/3], Step [3900/12942], Loss: 2.2008, Perplexity: 9.03180\n",
      "Epoch [2/3], Step [4000/12942], Loss: 2.1045, Perplexity: 8.20332\n",
      "Epoch [2/3], Step [4100/12942], Loss: 1.8158, Perplexity: 6.14610\n",
      "Epoch [2/3], Step [4200/12942], Loss: 2.1893, Perplexity: 8.92927\n",
      "Epoch [2/3], Step [4300/12942], Loss: 2.3117, Perplexity: 10.0915\n",
      "Epoch [2/3], Step [4400/12942], Loss: 2.2542, Perplexity: 9.52721\n",
      "Epoch [2/3], Step [4500/12942], Loss: 1.9188, Perplexity: 6.81317\n",
      "Epoch [2/3], Step [4600/12942], Loss: 2.2379, Perplexity: 9.37341\n",
      "Epoch [2/3], Step [4700/12942], Loss: 2.1357, Perplexity: 8.46313\n",
      "Epoch [2/3], Step [4800/12942], Loss: 1.9398, Perplexity: 6.95703\n",
      "Epoch [2/3], Step [4900/12942], Loss: 2.3120, Perplexity: 10.0942\n",
      "Epoch [2/3], Step [5000/12942], Loss: 1.8432, Perplexity: 6.31681\n",
      "Epoch [2/3], Step [5100/12942], Loss: 2.2818, Perplexity: 9.79435\n",
      "Epoch [2/3], Step [5200/12942], Loss: 2.0652, Perplexity: 7.88680\n",
      "Epoch [2/3], Step [5300/12942], Loss: 2.1238, Perplexity: 8.36322\n",
      "Epoch [2/3], Step [5400/12942], Loss: 1.9139, Perplexity: 6.77931\n",
      "Epoch [2/3], Step [5500/12942], Loss: 1.9725, Perplexity: 7.18849\n",
      "Epoch [2/3], Step [5600/12942], Loss: 1.9055, Perplexity: 6.72265\n",
      "Epoch [2/3], Step [5700/12942], Loss: 2.2003, Perplexity: 9.02799\n",
      "Epoch [2/3], Step [5800/12942], Loss: 2.4088, Perplexity: 11.1210\n",
      "Epoch [2/3], Step [5900/12942], Loss: 2.1489, Perplexity: 8.57564\n",
      "Epoch [2/3], Step [6000/12942], Loss: 2.2809, Perplexity: 9.78558\n",
      "Epoch [2/3], Step [6100/12942], Loss: 2.0630, Perplexity: 7.86972\n",
      "Epoch [2/3], Step [6200/12942], Loss: 1.7482, Perplexity: 5.74405\n",
      "Epoch [2/3], Step [6300/12942], Loss: 2.5948, Perplexity: 13.3943\n",
      "Epoch [2/3], Step [6400/12942], Loss: 1.9984, Perplexity: 7.37747\n",
      "Epoch [2/3], Step [6500/12942], Loss: 1.9804, Perplexity: 7.24540\n",
      "Epoch [2/3], Step [6600/12942], Loss: 2.9361, Perplexity: 18.8421\n",
      "Epoch [2/3], Step [6700/12942], Loss: 1.7614, Perplexity: 5.82068\n",
      "Epoch [2/3], Step [6800/12942], Loss: 2.1969, Perplexity: 8.99732\n",
      "Epoch [2/3], Step [6900/12942], Loss: 1.8323, Perplexity: 6.24832\n",
      "Epoch [2/3], Step [7000/12942], Loss: 2.3181, Perplexity: 10.1569\n",
      "Epoch [2/3], Step [7100/12942], Loss: 2.0935, Perplexity: 8.11314\n",
      "Epoch [2/3], Step [7200/12942], Loss: 1.8278, Perplexity: 6.22049\n",
      "Epoch [2/3], Step [7300/12942], Loss: 1.9895, Perplexity: 7.31161\n",
      "Epoch [2/3], Step [7400/12942], Loss: 2.0497, Perplexity: 7.76534\n",
      "Epoch [2/3], Step [7500/12942], Loss: 2.2258, Perplexity: 9.26056\n",
      "Epoch [2/3], Step [7600/12942], Loss: 2.0204, Perplexity: 7.54135\n",
      "Epoch [2/3], Step [7700/12942], Loss: 2.2119, Perplexity: 9.13347\n",
      "Epoch [2/3], Step [7800/12942], Loss: 2.1822, Perplexity: 8.86595\n",
      "Epoch [2/3], Step [7900/12942], Loss: 2.0462, Perplexity: 7.73824\n",
      "Epoch [2/3], Step [8000/12942], Loss: 2.1784, Perplexity: 8.83256\n",
      "Epoch [2/3], Step [8100/12942], Loss: 1.8840, Perplexity: 6.58009\n",
      "Epoch [2/3], Step [8200/12942], Loss: 2.0698, Perplexity: 7.92368\n",
      "Epoch [2/3], Step [8300/12942], Loss: 2.2074, Perplexity: 9.09213\n",
      "Epoch [2/3], Step [8400/12942], Loss: 1.8853, Perplexity: 6.58806\n",
      "Epoch [2/3], Step [8500/12942], Loss: 2.3613, Perplexity: 10.6052\n",
      "Epoch [2/3], Step [8600/12942], Loss: 1.9605, Perplexity: 7.10317\n",
      "Epoch [2/3], Step [8700/12942], Loss: 2.0542, Perplexity: 7.800760\n",
      "Epoch [2/3], Step [8800/12942], Loss: 1.7776, Perplexity: 5.91583\n",
      "Epoch [2/3], Step [8900/12942], Loss: 2.2057, Perplexity: 9.07660\n",
      "Epoch [2/3], Step [9000/12942], Loss: 1.9963, Perplexity: 7.36164\n",
      "Epoch [2/3], Step [9100/12942], Loss: 1.9032, Perplexity: 6.70725\n",
      "Epoch [2/3], Step [9200/12942], Loss: 2.1126, Perplexity: 8.26950\n",
      "Epoch [2/3], Step [9300/12942], Loss: 2.0706, Perplexity: 7.92977\n",
      "Epoch [2/3], Step [9400/12942], Loss: 1.7959, Perplexity: 6.02496\n",
      "Epoch [2/3], Step [9500/12942], Loss: 1.9352, Perplexity: 6.92514\n",
      "Epoch [2/3], Step [9600/12942], Loss: 1.8369, Perplexity: 6.27722\n",
      "Epoch [2/3], Step [9700/12942], Loss: 2.0518, Perplexity: 7.78169\n",
      "Epoch [2/3], Step [9800/12942], Loss: 2.1478, Perplexity: 8.56624\n",
      "Epoch [2/3], Step [9900/12942], Loss: 1.7687, Perplexity: 5.86333\n",
      "Epoch [2/3], Step [10000/12942], Loss: 1.9869, Perplexity: 7.2928\n",
      "Epoch [2/3], Step [10100/12942], Loss: 2.2641, Perplexity: 9.62255\n",
      "Epoch [2/3], Step [10200/12942], Loss: 1.9133, Perplexity: 6.77548\n",
      "Epoch [2/3], Step [10300/12942], Loss: 2.0586, Perplexity: 7.83479\n",
      "Epoch [2/3], Step [10400/12942], Loss: 2.0685, Perplexity: 7.91281\n",
      "Epoch [2/3], Step [10500/12942], Loss: 2.2633, Perplexity: 9.61527\n",
      "Epoch [2/3], Step [10600/12942], Loss: 1.8946, Perplexity: 6.65000\n",
      "Epoch [2/3], Step [10700/12942], Loss: 2.0612, Perplexity: 7.85554\n",
      "Epoch [2/3], Step [10800/12942], Loss: 1.8183, Perplexity: 6.16157\n",
      "Epoch [2/3], Step [10900/12942], Loss: 1.9727, Perplexity: 7.18989\n",
      "Epoch [2/3], Step [11000/12942], Loss: 2.2607, Perplexity: 9.58953\n",
      "Epoch [2/3], Step [11100/12942], Loss: 1.9367, Perplexity: 6.93617\n",
      "Epoch [2/3], Step [11200/12942], Loss: 2.4328, Perplexity: 11.3908\n",
      "Epoch [2/3], Step [11300/12942], Loss: 2.2243, Perplexity: 9.24738\n",
      "Epoch [2/3], Step [11400/12942], Loss: 2.1653, Perplexity: 8.71697\n",
      "Epoch [2/3], Step [11500/12942], Loss: 2.2644, Perplexity: 9.62581\n",
      "Epoch [2/3], Step [11600/12942], Loss: 2.1110, Perplexity: 8.25687\n",
      "Epoch [2/3], Step [11700/12942], Loss: 2.2418, Perplexity: 9.41014\n",
      "Epoch [2/3], Step [11800/12942], Loss: 1.8893, Perplexity: 6.61444\n",
      "Epoch [2/3], Step [11900/12942], Loss: 2.0590, Perplexity: 7.83799\n",
      "Epoch [2/3], Step [12000/12942], Loss: 1.9646, Perplexity: 7.13200\n",
      "Epoch [2/3], Step [12100/12942], Loss: 2.0834, Perplexity: 8.03216\n",
      "Epoch [2/3], Step [12200/12942], Loss: 2.1541, Perplexity: 8.62047\n",
      "Epoch [2/3], Step [12300/12942], Loss: 1.9722, Perplexity: 7.18659\n",
      "Epoch [2/3], Step [12400/12942], Loss: 2.0451, Perplexity: 7.73008\n",
      "Epoch [2/3], Step [12500/12942], Loss: 2.3154, Perplexity: 10.1285\n",
      "Epoch [2/3], Step [12600/12942], Loss: 1.8448, Perplexity: 6.32658\n",
      "Epoch [2/3], Step [12700/12942], Loss: 1.7282, Perplexity: 5.63059\n",
      "Epoch [2/3], Step [12800/12942], Loss: 1.9874, Perplexity: 7.29652\n",
      "Epoch [2/3], Step [12900/12942], Loss: 1.9795, Perplexity: 7.23940\n",
      "Epoch [3/3], Step [100/12942], Loss: 2.0391, Perplexity: 7.6834335\n",
      "Epoch [3/3], Step [200/12942], Loss: 2.0051, Perplexity: 7.42703\n",
      "Epoch [3/3], Step [300/12942], Loss: 1.9472, Perplexity: 7.00885\n",
      "Epoch [3/3], Step [400/12942], Loss: 1.6622, Perplexity: 5.27119\n",
      "Epoch [3/3], Step [500/12942], Loss: 2.0442, Perplexity: 7.72330\n",
      "Epoch [3/3], Step [600/12942], Loss: 1.9820, Perplexity: 7.25690\n",
      "Epoch [3/3], Step [700/12942], Loss: 1.9772, Perplexity: 7.22227\n",
      "Epoch [3/3], Step [800/12942], Loss: 2.1253, Perplexity: 8.37522\n",
      "Epoch [3/3], Step [900/12942], Loss: 2.2125, Perplexity: 9.13875\n",
      "Epoch [3/3], Step [1000/12942], Loss: 1.9189, Perplexity: 6.8133\n",
      "Epoch [3/3], Step [1100/12942], Loss: 1.5678, Perplexity: 4.79608\n",
      "Epoch [3/3], Step [1200/12942], Loss: 2.0993, Perplexity: 8.16088\n",
      "Epoch [3/3], Step [1300/12942], Loss: 1.7924, Perplexity: 6.00361\n",
      "Epoch [3/3], Step [1400/12942], Loss: 1.9415, Perplexity: 6.96909\n",
      "Epoch [3/3], Step [1500/12942], Loss: 1.7798, Perplexity: 5.92844\n",
      "Epoch [3/3], Step [1600/12942], Loss: 1.9773, Perplexity: 7.22305\n",
      "Epoch [3/3], Step [1700/12942], Loss: 1.7218, Perplexity: 5.59456\n",
      "Epoch [3/3], Step [1800/12942], Loss: 1.8560, Perplexity: 6.39815\n",
      "Epoch [3/3], Step [1900/12942], Loss: 2.5142, Perplexity: 12.3570\n",
      "Epoch [3/3], Step [2000/12942], Loss: 2.2045, Perplexity: 9.06545\n",
      "Epoch [3/3], Step [2100/12942], Loss: 1.9403, Perplexity: 6.96117\n",
      "Epoch [3/3], Step [2200/12942], Loss: 1.9648, Perplexity: 7.13355\n",
      "Epoch [3/3], Step [2300/12942], Loss: 1.8568, Perplexity: 6.40330\n",
      "Epoch [3/3], Step [2400/12942], Loss: 1.8960, Perplexity: 6.65923\n",
      "Epoch [3/3], Step [2500/12942], Loss: 2.2966, Perplexity: 9.94062\n",
      "Epoch [3/3], Step [2600/12942], Loss: 2.0631, Perplexity: 7.87051\n",
      "Epoch [3/3], Step [2700/12942], Loss: 2.4077, Perplexity: 11.1089\n",
      "Epoch [3/3], Step [2800/12942], Loss: 2.3603, Perplexity: 10.5940\n",
      "Epoch [3/3], Step [2900/12942], Loss: 1.8154, Perplexity: 6.14370\n",
      "Epoch [3/3], Step [3000/12942], Loss: 1.9770, Perplexity: 7.22097\n",
      "Epoch [3/3], Step [3100/12942], Loss: 2.0481, Perplexity: 7.75302\n",
      "Epoch [3/3], Step [3200/12942], Loss: 2.1125, Perplexity: 8.26850\n",
      "Epoch [3/3], Step [3300/12942], Loss: 1.8053, Perplexity: 6.08185\n",
      "Epoch [3/3], Step [3400/12942], Loss: 2.1003, Perplexity: 8.16889\n",
      "Epoch [3/3], Step [3500/12942], Loss: 1.6806, Perplexity: 5.36899\n",
      "Epoch [3/3], Step [3600/12942], Loss: 2.2158, Perplexity: 9.16908\n",
      "Epoch [3/3], Step [3700/12942], Loss: 1.7290, Perplexity: 5.63528\n",
      "Epoch [3/3], Step [3800/12942], Loss: 1.8856, Perplexity: 6.59007\n",
      "Epoch [3/3], Step [3900/12942], Loss: 1.9216, Perplexity: 6.83171\n",
      "Epoch [3/3], Step [4000/12942], Loss: 2.0032, Perplexity: 7.41251\n",
      "Epoch [3/3], Step [4100/12942], Loss: 2.2274, Perplexity: 9.27593\n",
      "Epoch [3/3], Step [4200/12942], Loss: 1.8662, Perplexity: 6.46356\n",
      "Epoch [3/3], Step [4300/12942], Loss: 1.8424, Perplexity: 6.31158\n",
      "Epoch [3/3], Step [4400/12942], Loss: 2.1098, Perplexity: 8.24680\n",
      "Epoch [3/3], Step [4500/12942], Loss: 1.8641, Perplexity: 6.45002\n",
      "Epoch [3/3], Step [4600/12942], Loss: 1.8224, Perplexity: 6.18645\n",
      "Epoch [3/3], Step [4700/12942], Loss: 1.7004, Perplexity: 5.47610\n",
      "Epoch [3/3], Step [4800/12942], Loss: 2.0440, Perplexity: 7.72164\n",
      "Epoch [3/3], Step [4900/12942], Loss: 2.3059, Perplexity: 10.0337\n",
      "Epoch [3/3], Step [5000/12942], Loss: 1.7546, Perplexity: 5.78142\n",
      "Epoch [3/3], Step [5100/12942], Loss: 2.0029, Perplexity: 7.41075\n",
      "Epoch [3/3], Step [5200/12942], Loss: 2.1362, Perplexity: 8.46687\n",
      "Epoch [3/3], Step [5300/12942], Loss: 2.2172, Perplexity: 9.18182\n",
      "Epoch [3/3], Step [5400/12942], Loss: 1.8993, Perplexity: 6.68153\n",
      "Epoch [3/3], Step [5500/12942], Loss: 2.2018, Perplexity: 9.04121\n",
      "Epoch [3/3], Step [5600/12942], Loss: 2.1208, Perplexity: 8.33797\n",
      "Epoch [3/3], Step [5700/12942], Loss: 1.8102, Perplexity: 6.11176\n",
      "Epoch [3/3], Step [5800/12942], Loss: 1.9941, Perplexity: 7.34594\n",
      "Epoch [3/3], Step [5900/12942], Loss: 2.3235, Perplexity: 10.2117\n",
      "Epoch [3/3], Step [6000/12942], Loss: 1.9962, Perplexity: 7.36133\n",
      "Epoch [3/3], Step [6100/12942], Loss: 1.7131, Perplexity: 5.54615\n",
      "Epoch [3/3], Step [6200/12942], Loss: 2.2776, Perplexity: 9.75324\n",
      "Epoch [3/3], Step [6300/12942], Loss: 1.9947, Perplexity: 7.34981\n",
      "Epoch [3/3], Step [6400/12942], Loss: 2.1474, Perplexity: 8.56246\n",
      "Epoch [3/3], Step [6500/12942], Loss: 2.0324, Perplexity: 7.63283\n",
      "Epoch [3/3], Step [6600/12942], Loss: 1.9102, Perplexity: 6.75435\n",
      "Epoch [3/3], Step [6700/12942], Loss: 2.2981, Perplexity: 9.95535\n",
      "Epoch [3/3], Step [6800/12942], Loss: 1.9098, Perplexity: 6.75171\n",
      "Epoch [3/3], Step [6900/12942], Loss: 2.0372, Perplexity: 7.66901\n",
      "Epoch [3/3], Step [7000/12942], Loss: 1.8794, Perplexity: 6.54935\n",
      "Epoch [3/3], Step [7100/12942], Loss: 1.8545, Perplexity: 6.38821\n",
      "Epoch [3/3], Step [7200/12942], Loss: 2.3633, Perplexity: 10.6264\n",
      "Epoch [3/3], Step [7300/12942], Loss: 1.9426, Perplexity: 6.97690\n",
      "Epoch [3/3], Step [7400/12942], Loss: 2.0787, Perplexity: 7.99432\n",
      "Epoch [3/3], Step [7500/12942], Loss: 1.8607, Perplexity: 6.42859\n",
      "Epoch [3/3], Step [7600/12942], Loss: 1.9723, Perplexity: 7.18755\n",
      "Epoch [3/3], Step [7700/12942], Loss: 2.1985, Perplexity: 9.01183\n",
      "Epoch [3/3], Step [7800/12942], Loss: 2.1999, Perplexity: 9.02433\n",
      "Epoch [3/3], Step [7900/12942], Loss: 2.0241, Perplexity: 7.56950\n",
      "Epoch [3/3], Step [8000/12942], Loss: 1.9867, Perplexity: 7.29153\n",
      "Epoch [3/3], Step [8100/12942], Loss: 2.0589, Perplexity: 7.83748\n",
      "Epoch [3/3], Step [8200/12942], Loss: 2.1650, Perplexity: 8.71497\n",
      "Epoch [3/3], Step [8300/12942], Loss: 1.7651, Perplexity: 5.84226\n",
      "Epoch [3/3], Step [8400/12942], Loss: 1.7746, Perplexity: 5.89801\n",
      "Epoch [3/3], Step [8500/12942], Loss: 1.7319, Perplexity: 5.65148\n",
      "Epoch [3/3], Step [8600/12942], Loss: 1.8280, Perplexity: 6.22177\n",
      "Epoch [3/3], Step [8700/12942], Loss: 2.3686, Perplexity: 10.6828\n",
      "Epoch [3/3], Step [8800/12942], Loss: 1.9649, Perplexity: 7.13437\n",
      "Epoch [3/3], Step [8900/12942], Loss: 1.9758, Perplexity: 7.21266\n",
      "Epoch [3/3], Step [9000/12942], Loss: 2.2934, Perplexity: 9.90856\n",
      "Epoch [3/3], Step [9100/12942], Loss: 2.0484, Perplexity: 7.75537\n",
      "Epoch [3/3], Step [9200/12942], Loss: 1.8917, Perplexity: 6.63033\n",
      "Epoch [3/3], Step [9300/12942], Loss: 2.0550, Perplexity: 7.80688\n",
      "Epoch [3/3], Step [9400/12942], Loss: 1.9689, Perplexity: 7.16265\n",
      "Epoch [3/3], Step [9500/12942], Loss: 1.7238, Perplexity: 5.60578\n",
      "Epoch [3/3], Step [9600/12942], Loss: 1.9455, Perplexity: 6.99697\n",
      "Epoch [3/3], Step [9700/12942], Loss: 1.9652, Perplexity: 7.13611\n",
      "Epoch [3/3], Step [9800/12942], Loss: 2.3019, Perplexity: 9.99365\n",
      "Epoch [3/3], Step [9900/12942], Loss: 1.8158, Perplexity: 6.14576\n",
      "Epoch [3/3], Step [10000/12942], Loss: 1.9083, Perplexity: 6.7413\n",
      "Epoch [3/3], Step [10100/12942], Loss: 2.1280, Perplexity: 8.39800\n",
      "Epoch [3/3], Step [10200/12942], Loss: 2.2408, Perplexity: 9.40111\n",
      "Epoch [3/3], Step [10300/12942], Loss: 1.8716, Perplexity: 6.49891\n",
      "Epoch [3/3], Step [10400/12942], Loss: 2.0198, Perplexity: 7.53663\n",
      "Epoch [3/3], Step [10500/12942], Loss: 2.0379, Perplexity: 7.67433\n",
      "Epoch [3/3], Step [10600/12942], Loss: 2.1902, Perplexity: 8.93706\n",
      "Epoch [3/3], Step [10700/12942], Loss: 2.7823, Perplexity: 16.1560\n",
      "Epoch [3/3], Step [10800/12942], Loss: 1.9840, Perplexity: 7.27180\n",
      "Epoch [3/3], Step [10900/12942], Loss: 2.2490, Perplexity: 9.47800\n",
      "Epoch [3/3], Step [11000/12942], Loss: 1.9867, Perplexity: 7.29143\n",
      "Epoch [3/3], Step [11100/12942], Loss: 1.8012, Perplexity: 6.05711\n",
      "Epoch [3/3], Step [11200/12942], Loss: 2.4367, Perplexity: 11.4355\n",
      "Epoch [3/3], Step [11300/12942], Loss: 1.9764, Perplexity: 7.21651\n",
      "Epoch [3/3], Step [11400/12942], Loss: 1.7648, Perplexity: 5.84057\n",
      "Epoch [3/3], Step [11500/12942], Loss: 1.9689, Perplexity: 7.16271\n",
      "Epoch [3/3], Step [11600/12942], Loss: 2.0378, Perplexity: 7.67381\n",
      "Epoch [3/3], Step [11700/12942], Loss: 2.5037, Perplexity: 12.2276\n",
      "Epoch [3/3], Step [11800/12942], Loss: 2.0621, Perplexity: 7.86237\n",
      "Epoch [3/3], Step [11900/12942], Loss: 2.0580, Perplexity: 7.83004\n",
      "Epoch [3/3], Step [12000/12942], Loss: 2.0693, Perplexity: 7.91968\n",
      "Epoch [3/3], Step [12100/12942], Loss: 2.0663, Perplexity: 7.89584\n",
      "Epoch [3/3], Step [12200/12942], Loss: 1.9348, Perplexity: 6.92295\n",
      "Epoch [3/3], Step [12300/12942], Loss: 1.7915, Perplexity: 5.99846\n",
      "Epoch [3/3], Step [12400/12942], Loss: 1.8595, Perplexity: 6.42032\n",
      "Epoch [3/3], Step [12500/12942], Loss: 2.5593, Perplexity: 12.9266\n",
      "Epoch [3/3], Step [12600/12942], Loss: 1.7684, Perplexity: 5.86153\n",
      "Epoch [3/3], Step [12700/12942], Loss: 1.8845, Perplexity: 6.58289\n",
      "Epoch [3/3], Step [12800/12942], Loss: 2.2202, Perplexity: 9.20940\n",
      "Epoch [3/3], Step [12900/12942], Loss: 1.9118, Perplexity: 6.76529\n",
      "Epoch [3/3], Step [12942/12942], Loss: 1.9550, Perplexity: 7.06410"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
